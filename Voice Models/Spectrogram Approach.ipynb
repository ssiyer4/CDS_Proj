{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-W0K25cdSol7"
      },
      "source": [
        "# Age Prediction from Spectrogram Input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNstHbefSxEm"
      },
      "source": [
        "Necessary Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqREm9faG4JI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import zipfile\n",
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "from tqdm.auto import tqdm\n",
        "import numpy as np\n",
        "import argparse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIfhVgntS3Jk"
      },
      "source": [
        "Google Drive Mount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H20bD6yHPUzp",
        "outputId": "9e8b4a07-132b-4c1e-f312-891a680732ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2CaiVLGS8bx"
      },
      "source": [
        "Extracting Spectrogram Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OL4FDxgUPi5H"
      },
      "outputs": [],
      "source": [
        "with zipfile.ZipFile(\"/content/drive/MyDrive/spectrograms.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/drive/MyDrive/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_mfBUqFQw-J",
        "outputId": "272d9592-207c-493d-de82-718ca874af5d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10839"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(os.listdir(\"/content/drive/MyDrive/spectrograms\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8ioP4PgTDaO"
      },
      "source": [
        "Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Make sure to change file paths to accurately match your file structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bmGGWfLHFXI"
      },
      "outputs": [],
      "source": [
        "class VoiceDataset(Dataset):\n",
        "    def __init__(self,\n",
        "                 csv_file = \"/content/drive/MyDrive/FINAL_AUDIO_FEATURES_10194.csv\",\n",
        "                 root_dir = \"/content/drive/MyDrive/spectrograms\", transform=None):\n",
        "\n",
        "        self.meta = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.meta)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.root_dir, f\"{self.meta.iloc[idx, 30][:-4]}png\")\n",
        "        image = Image.open(img_name).convert('RGB')\n",
        "        age = self.meta.iloc[idx, 31]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, age\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # Random brightness and contrast adjustments\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGS-FeQ5TSxM"
      },
      "source": [
        "VGG-16 Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYWLdyOMIkyK"
      },
      "outputs": [],
      "source": [
        "class AgePredictionVGG16(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AgePredictionVGG16, self).__init__()\n",
        "        vgg16 = models.vgg16(pretrained=True)\n",
        "        self.features = vgg16.features\n",
        "        self.avgpool = vgg16.avgpool\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6iaxgLnTVgW"
      },
      "source": [
        "Accuracy Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTnjg_UMI9i0"
      },
      "outputs": [],
      "source": [
        "def map_to_age_band(age):\n",
        "    return (age // 5) * 5\n",
        "\n",
        "def calculate_accuracy(predictions, labels, tolerance):\n",
        "    correct = 0\n",
        "    total = len(labels)\n",
        "    for pred, label in zip(predictions, labels):\n",
        "        if abs(pred - label) <= tolerance:\n",
        "            correct += 1\n",
        "    accuracy = (correct / total) * 100\n",
        "    return round(accuracy, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4DLWPG7TjKb"
      },
      "source": [
        "Training, Validation, and Testing Loop for VGG-16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztchCXG5TU6Y"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(voice_model, train_data, optimizer, criterion) -> None:\n",
        "    \"\"\"\n",
        "    Trains VGG16 for one epoch, for age prediction\n",
        "    :param voice_model: VGG16 model\n",
        "    :param train_data: training data\n",
        "    :param optimizer: optimizer\n",
        "    :param criterion: loss criterion\n",
        "    \"\"\"\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Using device:\", device)\n",
        "\n",
        "    voice_model.train()\n",
        "\n",
        "    for imgs, targets in tqdm(train_data):\n",
        "\n",
        "        imgs = imgs.to(device)\n",
        "        targets = targets.to(torch.float32).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = voice_model(imgs)\n",
        "        outputs = outputs.to(torch.float32)\n",
        "        mse_loss = criterion(outputs.squeeze(), targets.float())\n",
        "        rmse_loss = torch.sqrt(mse_loss) # Compute the RMSE from MSE\n",
        "        # total_loss = rmse_loss + reg_term\n",
        "        rmse_loss.backward()\n",
        "        optimizer.step()\n",
        "        print(rmse_loss.item())\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_one_epoch(voice_model, val_data, epoch, criterion):\n",
        "    \"\"\"\n",
        "    Evaluates VGG16 for one epoch, for age prediction\n",
        "    :param voice_model: VGG16 model\n",
        "    :param train_data: validation data\n",
        "    :param optimizer: optimizer\n",
        "    :param criterion: loss criterion\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"device: \", device)\n",
        "    voice_model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, targets in tqdm(val_data):\n",
        "\n",
        "            imgs = imgs.to(device)\n",
        "            targets = targets.to(torch.float32).to(device)\n",
        "\n",
        "\n",
        "            preds = voice_model(imgs)\n",
        "            preds = preds.to(torch.float32)\n",
        "            mse_loss = criterion(preds.squeeze(), targets.float())\n",
        "            rmse_loss = torch.sqrt(mse_loss)\n",
        "            print(rmse_loss.item())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def test_voice_model(voice_model, test_data, criterion):\n",
        "    \"\"\"\n",
        "    Tests VGG16 for one epoch, for age prediction\n",
        "    :param voice_model: VGG16 model\n",
        "    :param train_data: test data\n",
        "    :param optimizer: optimizer\n",
        "    :param criterion: loss criterion\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    voice_model.eval()\n",
        "\n",
        "    acc = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, targets in tqdm(test_data):\n",
        "\n",
        "            imgs = imgs.to(device)\n",
        "            targets = targets.to(torch.float32).to(device)\n",
        "\n",
        "            preds = voice_model(imgs)\n",
        "            preds = preds.to(torch.float32)\n",
        "            mse_loss = criterion(preds.squeeze(), targets.float())\n",
        "            rmse_loss = torch.sqrt(mse_loss)\n",
        "            print(rmse_loss.item())\n",
        "\n",
        "            batch_acc = calculate_accuracy(preds.cpu().squeeze().detach().numpy().tolist(), targets.cpu().detach().numpy().tolist(), 6)\n",
        "\n",
        "            acc.append(batch_acc)\n",
        "\n",
        "\n",
        "    final_acc = np.average(acc)\n",
        "    print(\"FINAL ACCURACY:\", final_acc)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "voice_dataset = VoiceDataset(transform=transform)\n",
        "train_data_tmp, val_data_tmp, test_data_tmp = torch.utils.data.random_split(voice_dataset, [0.8, 0.1, 0.1], generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "train_data = DataLoader(\n",
        "    train_data_tmp,\n",
        "    batch_size=128,\n",
        "    shuffle=False,\n",
        ")\n",
        "val_data = DataLoader(\n",
        "    val_data_tmp,\n",
        "    batch_size=128,\n",
        "    shuffle=False,\n",
        ")\n",
        "test_data = DataLoader(\n",
        "    test_data_tmp,\n",
        "    batch_size=128,\n",
        "    shuffle=False,\n",
        ")\n",
        "print(\"train_data:\", train_data)\n",
        "print(\"val_data:\", val_data)\n",
        "print(\"test_data:\", test_data)\n",
        "\n",
        "voice_model = AgePredictionVGG16()\n",
        "voice_model = voice_model.to(device)\n",
        "\n",
        "params = voice_model.parameters()\n",
        "optimizer = torch.optim.Adam(\n",
        "    params, lr=0.0005, weight_decay=0.0005\n",
        ")\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(40):\n",
        "    print(\"training epoch:\", epoch)\n",
        "    train_one_epoch(voice_model, train_data, optimizer, criterion)\n",
        "    print(\"evaluating epoch:\", epoch)\n",
        "    evaluate_one_epoch(voice_model, val_data, epoch, criterion)\n",
        "    pass\n",
        "\n",
        "torch.save(voice_model, \"/content/drive/MyDrive/vgg16_v6.pt\")\n",
        "\n",
        "# Testing Loop\n",
        "\n",
        "voice_model_trained = torch.load(\"/content/drive/MyDrive/vgg16_v6.pt\", map_location=torch.device('cpu'))\n",
        "voice_model_trained.to(device)\n",
        "print(\"testing model: \", \"vgg16_v6.pt\")\n",
        "test_voice_model(voice_model_trained, test_data, criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtnoLhGXTyX4"
      },
      "source": [
        "MobileNetv2 Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xo7fSH93DBn2"
      },
      "outputs": [],
      "source": [
        "class MobileNetV2(nn.Module):\n",
        "    def __init__(self, num_classes=1):\n",
        "        super(MobileNetV2, self).__init__()\n",
        "        self.model = models.mobilenet_v2(pretrained=True)\n",
        "        self.model.classifier[1] = nn.Linear(1280, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FySjdTKiTyvE"
      },
      "source": [
        "Training, Validation, and Testing Loop for MobileNetv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxhRCnq6CHLc"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from tqdm.auto import tqdm\n",
        "import numpy as np\n",
        "import argparse\n",
        "import torch\n",
        "\n",
        "def train_one_epoch(voice_model, train_data, optimizer, criterion) -> None:\n",
        "    \"\"\"\n",
        "    Trains MobileNetV2 for one epoch, for age prediction\n",
        "    :param voice_model: MobileNetV2 model\n",
        "    :param train_data: training data\n",
        "    :param optimizer: optimizer\n",
        "    :param criterion: loss criterion\n",
        "    \"\"\"\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Using device:\", device)\n",
        "\n",
        "    voice_model.train()\n",
        "\n",
        "    for imgs, targets in tqdm(train_data):\n",
        "\n",
        "        imgs = imgs.to(device)\n",
        "        targets = targets.to(torch.float32).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = voice_model(imgs)\n",
        "        outputs = outputs.to(torch.float32)\n",
        "        mse_loss = criterion(outputs.squeeze(), targets.float())\n",
        "        rmse_loss = torch.sqrt(mse_loss) # Compute the RMSE from MSE\n",
        "        rmse_loss.backward()\n",
        "        optimizer.step()\n",
        "        print(rmse_loss.item())\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_one_epoch(voice_model, val_data, epoch, criterion):\n",
        "    \"\"\"\n",
        "    Evaluates MobileNetV2 for one epoch, for age prediction\n",
        "    :param voice_model: MobileNetV2 model\n",
        "    :param train_data: validation data\n",
        "    :param optimizer: optimizer\n",
        "    :param criterion: loss criterion\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"device: \", device)\n",
        "    voice_model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, targets in tqdm(val_data):\n",
        "\n",
        "            imgs = imgs.to(device)\n",
        "            targets = targets.to(torch.float32).to(device)\n",
        "\n",
        "\n",
        "            preds = voice_model(imgs)\n",
        "            preds = preds.to(torch.float32)\n",
        "            mse_loss = criterion(preds.squeeze(), targets.float())\n",
        "            rmse_loss = torch.sqrt(mse_loss)\n",
        "            print(rmse_loss.item())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def test_voice_model(voice_model, test_data, criterion):\n",
        "    \"\"\"\n",
        "    Tests MobileNetV2 for one epoch, for age prediction\n",
        "    :param voice_model: MobileNetV2 model\n",
        "    :param train_data: test data\n",
        "    :param optimizer: optimizer\n",
        "    :param criterion: loss criterion\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    voice_model.eval()\n",
        "\n",
        "    acc = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, targets in tqdm(test_data):\n",
        "\n",
        "            imgs = imgs.to(device)\n",
        "            targets = targets.to(torch.float32).to(device)\n",
        "\n",
        "            preds = voice_model(imgs)\n",
        "            preds = preds.to(torch.float32)\n",
        "            mse_loss = criterion(preds.squeeze(), targets.float())\n",
        "            rmse_loss = torch.sqrt(mse_loss)\n",
        "            print(rmse_loss.item())\n",
        "\n",
        "            batch_acc = calculate_accuracy(preds.cpu().squeeze().detach().numpy().tolist(), targets.cpu().detach().numpy().tolist(), 6)\n",
        "\n",
        "            acc.append(batch_acc)\n",
        "\n",
        "\n",
        "    final_acc = np.average(acc)\n",
        "    print(\"FINAL ACCURACY:\", final_acc)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "voice_dataset = VoiceDataset(transform=transform)\n",
        "train_data_tmp, val_data_tmp, test_data_tmp = torch.utils.data.random_split(voice_dataset, [0.8, 0.1, 0.1], generator=torch.Generator().manual_seed(42))\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "train_data = DataLoader(\n",
        "    train_data_tmp,\n",
        "    batch_size=128,\n",
        "    shuffle=False,\n",
        ")\n",
        "val_data = DataLoader(\n",
        "    val_data_tmp,\n",
        "    batch_size=128,\n",
        "    shuffle=False,\n",
        ")\n",
        "test_data = DataLoader(\n",
        "    test_data_tmp,\n",
        "    batch_size=128,\n",
        "    shuffle=False,\n",
        ")\n",
        "print(\"train_data:\", train_data)\n",
        "print(\"val_data:\", val_data)\n",
        "print(\"test_data:\", test_data)\n",
        "\n",
        "voice_model = MobileNetV2()\n",
        "voice_model = voice_model.to(device)\n",
        "\n",
        "params = voice_model.parameters()\n",
        "optimizer = torch.optim.Adam(\n",
        "    params, lr=0.00004, weight_decay=0.0005\n",
        ")\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(40):\n",
        "    print(\"training epoch:\", epoch)\n",
        "    train_one_epoch(voice_model, train_data, optimizer, criterion)\n",
        "    print(\"evaluating epoch:\", epoch)\n",
        "    evaluate_one_epoch(voice_model, val_data, epoch, criterion)\n",
        "    pass\n",
        "\n",
        "torch.save(voice_model, \"/content/drive/MyDrive/mbnetv4.pt\")\n",
        "\n",
        "# Testing Loop\n",
        "\n",
        "voice_model_trained = torch.load(\"/content/drive/MyDrive/mbnetv4.pt\", map_location=torch.device('cpu'))\n",
        "voice_model_trained.to(device)\n",
        "print(\"testing model: \", \"mbnetv4.pt\")\n",
        "test_voice_model(voice_model_trained, test_data, criterion)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
